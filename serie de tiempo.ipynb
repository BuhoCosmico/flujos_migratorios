{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "import seaborn as sns\n",
    "import os\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar el conjunto de datos en un DataFrame\n",
    "df = pd.read_csv(\"txt_eda/unpopulation_dataportal_20230223061750.csv\")\n",
    "\n",
    "# Agrupar los datos por el valor de la columna \"location\"\n",
    "grupos = df.groupby(\"location\")\n",
    "\n",
    "for pais, datos_pais in grupos:\n",
    "    # Crear el directorio para el país si no existe\n",
    "    directorio_pais = f\"{pais}\"\n",
    "    if not os.path.exists(directorio_pais):\n",
    "        os.makedirs(directorio_pais)\n",
    "\n",
    "# Iterar sobre los grupos y dividirlos en subconjuntos separados para cada valor único en la columna \"indicatorshortname\"\n",
    "for grupo_nombre, grupo_datos in grupos:\n",
    "    for indicador_nombre, indicador_datos in grupo_datos.groupby(\"indicatorshortname\"):\n",
    "        # Guardar el subconjunto como un archivo CSV separado\n",
    "        archivo_nombre = f\"{grupo_nombre}_{indicador_nombre}.csv\"\n",
    "        indicador_datos.to_csv(archivo_nombre, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio para los gráficos si no existe\n",
    "graphs_dir = \"txt_eda/paises/graphs/proph\"\n",
    "if not os.path.exists(graphs_dir):\n",
    "    os.makedirs(graphs_dir)\n",
    "\n",
    "\n",
    "# Obtener lista de nombres de archivos\n",
    "file_names = os.listdir(\"txt_eda/paises/0 aa crude rate net total migrnt\")\n",
    "\n",
    "# Iterar sobre los nombres de archivo y crear gráficos\n",
    "for file_name in file_names:\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        path = os.path.join(\"txt_eda/paises/0 aa crude rate net total migrnt\", file_name)\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # Crear un gráfico de línea para el DataFrame actual\n",
    "        fig, axs = plt.subplots(2, figsize=(10, 10), facecolor='w')\n",
    "        elemento = df[\"indicatorshortname\"].iloc[0]\n",
    "        axs[0].plot(df[\"time\"], df[\"value\"])\n",
    "        axs[0].set_xlabel(\"Fecha\", fontsize=14)\n",
    "        axs[0].set_ylabel(\"Valor\", fontsize=14)\n",
    "        axs[0].set_title(elemento, fontsize=16)\n",
    "        axs[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "        # Crear un gráfico de dispersión para el DataFrame actual\n",
    "        axs[1].scatter(df[\"time\"], df[\"value\"])\n",
    "        axs[1].set_xlabel(\"Fecha\", fontsize=14)\n",
    "        axs[1].set_ylabel(\"Valor\", fontsize=14)\n",
    "        axs[1].set_title(elemento, fontsize=16)\n",
    "        axs[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "        # Ajustar los espacios entre los gráficos\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # Cambiar caracteres no permitidos en el nombre del archivo por guiones bajos\n",
    "        file_name = file_name.replace(\":\", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\"*\", \"_\").replace(\"?\", \"_\").replace(\"\\\"\", \"_\").replace(\"<\", \"_\").replace(\">\", \"_\").replace(\"|\", \"_\")\n",
    "\n",
    "        # Guardar el gráfico\n",
    "        graph_path = os.path.join(graphs_dir, file_name.replace(\".csv\", \".png\"))\n",
    "        plt.savefig(graph_path)\n",
    "\n",
    "        # Cerrar la figura\n",
    "        plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"txt_eda/paises/00paises/favorable\"\n",
    "\n",
    "# Obtener lista de nombres de archivos\n",
    "file_names = os.listdir(dir_path)\n",
    "\n",
    "# Iterar sobre los nombres de archivo y cambiar las comas por puntos en la columna \"value\"\n",
    "for file_name in file_names:\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        path = os.path.join(dir_path, file_name)\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # Eliminar valores nulos o vacíos en la columna \"value\"\n",
    "        df = df.dropna(subset=[\"value\"])\n",
    "\n",
    "        # Convertir la columna \"value\" a string\n",
    "        df[\"value\"] = df[\"value\"].astype(str)\n",
    "\n",
    "        # Reemplazar comas por puntos en la columna \"value\"\n",
    "        df[\"value\"] = df[\"value\"].str.replace(\",\", \".\")\n",
    "\n",
    "        # Guardar el dataframe modificado en el mismo archivo\n",
    "        df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:49:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:49:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:50:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:50:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Directorios con los datos\n",
    "favorable_dir = \"txt_eda/paises/00paises/favorable\"\n",
    "desfavorable_dir = \"txt_eda/paises/00paises/desfavorable\"\n",
    "\n",
    "# Función para leer y formatear los datos\n",
    "def read_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[[\"time\", \"value\"]]\n",
    "    df = df.rename(columns={\"time\": \"ds\", \"value\": \"y\"})\n",
    "    df[\"ds\"] = pd.to_datetime(df[\"ds\"], format=\"%Y\")\n",
    "    return df\n",
    "\n",
    "# Función para crear y guardar el gráfico\n",
    "def plot_and_save(df, title, file_name):\n",
    "    m = Prophet()\n",
    "    m.fit(df)\n",
    "    future = m.make_future_dataframe(periods=30, freq='Y')\n",
    "    forecast = m.predict(future)\n",
    "    fig = m.plot(forecast)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Año\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.savefig(file_name)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Crear directorios para los gráficos si no existen\n",
    "graphs_dir_fav = \"txt_eda/paises/00paises/favorable/graphs\"\n",
    "graphs_dir_desfav = \"txt_eda/paises/00paises/desfavorable/graphs\"\n",
    "for dir_path in [graphs_dir_fav, graphs_dir_desfav]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "# Iterar sobre los archivos y crear los gráficos\n",
    "for file_name in os.listdir(favorable_dir):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(favorable_dir, file_name)\n",
    "        df = read_data(file_path)\n",
    "        title = file_name.replace(\".csv\", \"\")\n",
    "        graph_path = os.path.join(graphs_dir_fav, file_name.replace(\".csv\", \".png\"))\n",
    "        plot_and_save(df, title, graph_path)\n",
    "\n",
    "for file_name in os.listdir(desfavorable_dir):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(desfavorable_dir, file_name)\n",
    "        df = read_data(file_path)\n",
    "        title = file_name.replace(\".csv\", \"\")\n",
    "        graph_path = os.path.join(graphs_dir_desfav, file_name.replace(\".csv\", \".png\"))\n",
    "        plot_and_save(df, title, graph_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94b726c8f5322570b40f638d72bd6cd9fb0c927e05f66e6f75c68aa69cf05a4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
